# Supervised-Machine-Learning-Projects-Fraud-Analytics
**Account Originaiton Fraud project (Credit Card Fraud Applications)

****Business Problem and Process Overview:**
This project aims to investigate identity fraud, which is the most prevalent sort of account origination fraud. Fraudsters apply for a product or service using different identities than their own. There are three types of identity fraud; Identity theft: fraudsters use real but stolen identities, identity manipulation: fraudsters alter their own identities (ssn, dob, name), synthetic fraud: fraudsters create entirely fabricated identities. Our supervised fraud algorithm examines all incoming applications and flags any that appear unusual and potentially fraudulent. The procedure is as follows: a consumer first applies for a credit card at a bank, and then the bank submits the application to a credit bureau, which assesses the applicant's fraud risk based on past data and returns the application to the bank. The bank then decides whether to offer a credit card to the customer.

**Predictive Analytics Pipeline:**
The original dataset has 1,000,000 records and 10 columns of personal identifying information from applications in 2016. Records have been labeled to indicate whether the application is fraudulent. We didn't consider the first two weeks of data for training or testing the model because it wasn't fully established. We divided the data into train and test till October. The last two months were set aside as a hold-out set (OOT) to evaluate the model's performance. We developed a Data Quality Report to understand the dataset's quality before building the fraud algorithm.
To create the fraud algorithm, we conducted a comprehensive data flow procedure. We cleaned the data by treating irrelevant and frivolous values. Then, using various combinations of personal identifying information and time variables, we created over 10,700 variables, scaled them all, and used filter and wrapper sequentially (feature selection) to select the most important predictors. We then performed baseline modeling (logistic regression) before experimenting with five non-linear models by tuning hyperparameters. Finally, assessing model performance on out-of-sample data, we chose the optimal model with the best model performance (FDR).

**Results:**
Finally, we had two models that performed admirably. Random Forest and Gradient Boosting Tree. After carefully examining the trade-off between complexity and accuracy, Gradient Boosting, with 100 trees and a maximum depth of 15 for each tree, was the simplest model to give us the best fraud detection rate of 53.73% FDR at 3% on out of time data. Please see the Results section for a complete description of our top model's training, testing, and out-of-time data performance.
